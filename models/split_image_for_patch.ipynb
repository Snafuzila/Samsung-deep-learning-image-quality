{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VXTEv7P19X2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "def process_folder_through_cnn(folder_path, model, batch_size=64, device='cuda'):\n",
        "    \"\"\"\n",
        "    Reads images from a folder, cuts them into 50x50 patches (preserving edges),\n",
        "    and runs them through a provided CNN model in batches.\n",
        "    \"\"\"\n",
        "    # 1. Setup\n",
        "    model = model.to(device)\n",
        "    model.eval() # Set model to evaluation mode (disables dropout, etc.)\n",
        "\n",
        "    # Get all valid image files in the folder\n",
        "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')\n",
        "    image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
        "                   if f.lower().endswith(valid_extensions)]\n",
        "\n",
        "    all_results = []\n",
        "    patch_size = 50\n",
        "\n",
        "    # Disable gradient tracking to save memory and speed up inference\n",
        "    with torch.no_grad():\n",
        "        for img_path in image_files:\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Convert BGR (OpenCV default) to RGB (Standard for CNNs)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            h, w, _ = img.shape\n",
        "\n",
        "            # 2. Calculate coordinates (no missed pixels, snaps to the edge)\n",
        "            y_coords = sorted(list(set(list(range(0, max(1, h - patch_size), patch_size)) + [max(0, h - patch_size)])))\n",
        "            x_coords = sorted(list(set(list(range(0, max(1, w - patch_size), patch_size)) + [max(0, w - patch_size)])))\n",
        "\n",
        "            patches = []\n",
        "\n",
        "            # 3. Cut into 50x50 patches\n",
        "            for y in y_coords:\n",
        "                for x in x_coords:\n",
        "                    patch = img[y:y+patch_size, x:x+patch_size]\n",
        "                    # Ensure patch is exactly 50x50 (skips if original image is smaller than 50x50)\n",
        "                    if patch.shape[0] == patch_size and patch.shape[1] == patch_size:\n",
        "                        patches.append(patch)\n",
        "\n",
        "            if not patches:\n",
        "                continue\n",
        "\n",
        "            # 4. Prepare for the CNN (Convert to Tensor: Batch, Channels, Height, Width)\n",
        "            # PyTorch expects dimensions to be (N, C, H, W) and normalized to [0, 1]\n",
        "            import numpy as np\n",
        "            patches_array = np.array(patches)\n",
        "            patches_tensor = torch.from_numpy(patches_array).permute(0, 3, 1, 2).float() / 255.0\n",
        "\n",
        "            # 5. Run through the model in chunks (batches) to prevent GPU out-of-memory errors\n",
        "            image_results = []\n",
        "            for i in range(0, len(patches_tensor), batch_size):\n",
        "                batch = patches_tensor[i : i + batch_size].to(device)\n",
        "\n",
        "                # Pass batch through your existing CNN\n",
        "                output = model(batch)\n",
        "\n",
        "                # Move predictions back to CPU memory immediately so GPU RAM doesn't fill up\n",
        "                image_results.append(output.cpu())\n",
        "\n",
        "            # Store results for this specific image\n",
        "            all_results.append({\n",
        "                'image_path': img_path,\n",
        "                'predictions': torch.cat(image_results, dim=0) # Combines all batches back into one tensor\n",
        "            })\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# --- Example Usage ---\n",
        "# my_existing_model = MyCNN()\n",
        "# my_existing_model.load_state_dict(torch.load('weights.pth'))\n",
        "# results = process_folder_through_cnn('/path/to/images', my_existing_model, batch_size=128, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdDxGuwB5LZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}