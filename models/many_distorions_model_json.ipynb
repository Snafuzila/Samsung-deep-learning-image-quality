{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "id": "ZYabiO7yeP2k",
    "ExecuteTime": {
     "end_time": "2026-02-19T15:50:09.779762600Z",
     "start_time": "2026-02-19T15:49:00.961031100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Config & Paths\n",
    "\n",
    "IMG_DIR = Path(\"C:\\Recovered\\BOAZ\\study\\projects\\samsung\\samsung_data\")\n",
    "JSON_PATH = Path(r\"C:\\Recovered\\BOAZ\\study\\projects\\samsung\\samsung_data\\annotations.json\")\n",
    "\n",
    "IMAGE_SIZE = 50                                 # Good balance for simple CNN + speed\n",
    "BATCH_SIZE = 256 # chat says 512-1024 might be possible\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_WORKERS = 4 if torch.cuda.is_available() else 0\n",
    "\n",
    "# Make sure paths exist\n",
    "assert IMG_DIR.exists(), f\"Image folder not found: {IMG_DIR}\"\n",
    "assert JSON_PATH.exists(), f\"JSON not found: {JSON_PATH}\""
   ],
   "metadata": {
    "id": "-naxxANheWR3",
    "ExecuteTime": {
     "end_time": "2026-02-19T15:59:58.558676600Z",
     "start_time": "2026-02-19T15:59:58.523893900Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "collapsed": true,
    "id": "GnKvRQDkav3x",
    "outputId": "ff104e17-77e7-4b4e-a0da-ac57df1e7c7a",
    "ExecuteTime": {
     "start_time": "2026-02-19T16:30:46.787027100Z"
    }
   },
   "source": [
    "# 1. Load the JSON (adding lines=True just in case it's a JSONL file)\n",
    "\n",
    "try:\n",
    "\n",
    "    df = pd.read_json(JSON_PATH)\n",
    "\n",
    "except ValueError:\n",
    "\n",
    "    # If the above fails, it's likely a 'JSON Lines' format\n",
    "\n",
    "    df = pd.read_json(JSON_PATH, lines=True)\n",
    "\n",
    "\n",
    "\n",
    "# 2. Set your column name\n",
    "\n",
    "# Based on your prompt, we are using 'artifact'\n",
    "\n",
    "label_column = 'artifact'\n",
    "\n",
    "\n",
    "\n",
    "# 3. Validation Check: Make sure the column actually exists\n",
    "\n",
    "if label_column not in df.columns:\n",
    "\n",
    "    print(f\"❌ Error: '{label_column}' not found. Available columns: {list(df.columns)}\")\n",
    "\n",
    "    # Stop here if the column is missing\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"✅ Original columns:\", list(df.columns))\n",
    "\n",
    "    print(f\"✅ Using label column: '{label_column}'\")\n",
    "\n",
    "\n",
    "\n",
    "    # 4. Create clean integer labels\n",
    "\n",
    "    # .unique() gives us the distinct artifact names\n",
    "\n",
    "    labels = sorted(df[label_column].unique())\n",
    "\n",
    "    label2idx = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "    idx2label = {i: label for label, i in label2idx.items()}\n",
    "\n",
    "\n",
    "\n",
    "    # Map the text labels (e.g., 'blur') to integers (e.g., 0)\n",
    "\n",
    "    df[\"label\"] = df[label_column].map(label2idx).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nClasses found:\", labels)\n",
    "\n",
    "    print(\"Number of classes:\", len(labels))\n",
    "\n",
    "\n",
    "\n",
    "    # 5. Stratified train/val split\n",
    "\n",
    "    # 'stratify' ensures both sets have the same % of each artifact type\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "\n",
    "        df,\n",
    "\n",
    "        test_size=0.2,\n",
    "\n",
    "        random_state=42, # Replacing SEED with a literal if not defined\n",
    "\n",
    "        stratify=df[\"label\"]\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"\\nTrain: {len(train_df)} images\")\n",
    "\n",
    "    print(f\"Val:   {len(val_df)} images\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class DistortionDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.img_dir / row[\"filename\"]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "id": "dM0y2kjidUGT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training transforms (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor()\n",
    "    # ,transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "     #                    std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation transforms (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "    # ,transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "     #                    std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = DistortionDataset(train_df, IMG_DIR, transform=train_transform)\n",
    "val_dataset   = DistortionDataset(val_df,   IMG_DIR, transform=val_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                         num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"DataLoaders ready!\")"
   ],
   "metadata": {
    "id": "kKkVOucsfbTH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Model\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: Input 3x50x50 -> Output 32x25x25\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), # in_channels, out_channels, stride, padding, dilation, group, bias\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # kernel_size=2, stride = kernel_size = 2, 128 → 64 → 32 → 16 → 8\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 12 * 12, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = SimpleCNN(num_classes=len(labels)).to(device)\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "metadata": {
    "id": "N_TEbWGafzGi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Input image: 3 × 128 × 128\n",
    "\n",
    "After 4 blocks of conv + maxpool(2): spatial size is divided by 2 four times\n",
    "128 ÷ 2 ÷ 2 ÷ 2 ÷ 2 = 8\n",
    "\n",
    "Last conv layer had 256 filters → feature map size = 256 × 8 × 8\n",
    "\n",
    "We need to turn this 3D tensor into 1D vector before Linear layer\n",
    "→ nn.Flatten() does that\n",
    "\n",
    "256 channels × 8 height × 8 width = 16384 numbers\n",
    "\n",
    "First linear layer: 16384 → 512\n",
    "\n",
    "Then dropout (randomly zero 50% of values during training → prevents overfitting)\n",
    "\n",
    "Final linear: 512 → number of your classes\n",
    "\n",
    "Classic VGG-style head."
   ],
   "metadata": {
    "id": "ffpwsBAKi1zS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Loss, Optimizer & Scheduler\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)"
   ],
   "metadata": {
    "id": "lXHtFgklgWwG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training Loop\n",
    "\n",
    "best_acc = 0.0\n",
    "history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # === Training ===\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100. * correct / total\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1:2d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_distortion_cnn.pth\")\n",
    "        print(f\"   → New best model saved! ({best_acc:.2f}%)\")"
   ],
   "metadata": {
    "id": "YVVM1o6hgrck"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot Training History\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "collapsed": true,
    "id": "Efj906u4hJSJ",
    "outputId": "77c06c19-59f4-4a9f-aa93-6b6fea6e7bc5"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-3943334777.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m12\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"train_loss\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Train Loss\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"val_loss\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Val Loss\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluation & Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "collapsed": true,
    "id": "2Zs8YgcShQYO",
    "outputId": "aea4e767-1ce0-49f9-e2c2-453edf5de1d8"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-2919844700.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclassification_report\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mall_preds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     71\u001B[0m     \u001B[0m_distributor_init\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m )\n\u001B[0;32m---> 73\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mbase\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mclone\u001B[0m  \u001B[0;31m# noqa: E402\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     74\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_show_versions\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mshow_versions\u001B[0m  \u001B[0;31m# noqa: E402\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_config\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mget_config\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mexceptions\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mInconsistentVersionWarning\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_estimator_html_repr\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_HTMLDocumentationLinkMixin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mestimator_html_repr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_metadata_requests\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_MetadataRequester\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_routing_enabled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_param_validation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mvalidate_parameter_constraints\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_joblib\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetadata_routing\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_bunch\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mBunch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_chunking\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgen_batches\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgen_even_slices\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_estimator_html_repr\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mestimator_html_repr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_chunking.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_config\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mget_config\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_param_validation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mInterval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidate_params\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_config\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mget_config\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mvalidation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_is_arraylike_not_scalar\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mget_config\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_get_config\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexceptions\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDataConversionWarning\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mNotFittedError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPositiveSpectrumWarning\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_array_api\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_is_numpy_namespace\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mget_namespace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeprecation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_deprecate_force_all_finite\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfixes\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mComplexWarning\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_preserve_dia_indices_dtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_array_api.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_config\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mget_config\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mfixes\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mparse_version\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0m_NUMPY_NAMESPACE_NAMES\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"numpy\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"array_api_compat.numpy\"\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/fixes.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msparse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstats\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    624\u001B[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001B[1;32m    625\u001B[0m                                DegenerateDataWarning, FitError)\n\u001B[0;32m--> 626\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_stats_py\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    627\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_variation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mvariation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mdistributions\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_stats_py.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;31m# See https://github.com/scipy/scipy/issues/15765#issuecomment-1875564522\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlinalg\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdistributions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_mstats_basic\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mmstats_basic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/distributions.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_distn_infrastructure\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mrv_discrete\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrv_continuous\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrv_frozen\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_continuous_distns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_discrete_distns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_continuous_distns.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m   6349\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6350\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6351\u001B[0;31m \u001B[0mlevy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlevy_gen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"levy\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6352\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6353\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, momtype, a, b, xtol, badvalue, name, longname, shapes, seed)\u001B[0m\n\u001B[1;32m   1892\u001B[0m                                   \u001B[0mlocscale_in\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'loc=0, scale=1'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1893\u001B[0m                                   locscale_out='loc, scale')\n\u001B[0;32m-> 1894\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_attach_methods\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1895\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1896\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlongname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001B[0m in \u001B[0;36m_attach_methods\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1926\u001B[0m         \"\"\"\n\u001B[1;32m   1927\u001B[0m         \u001B[0;31m# _attach_methods is responsible for calling _attach_argparser_methods\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1928\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_attach_argparser_methods\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1930\u001B[0m         \u001B[0;31m# nin correction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001B[0m in \u001B[0;36m_attach_argparser_methods\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    742\u001B[0m         \"\"\"\n\u001B[1;32m    743\u001B[0m         \u001B[0mns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 744\u001B[0;31m         \u001B[0mexec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parse_arg_template\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    745\u001B[0m         \u001B[0;31m# NB: attach to the instance, not class\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    746\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'_parse_args'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'_parse_args_stats'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'_parse_args_rvs'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<string>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ]
}
